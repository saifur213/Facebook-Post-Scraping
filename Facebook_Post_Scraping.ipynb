{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMww16ONUwbPZcJj7f549iA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":46,"metadata":{"id":"AzKdKEQKhaFH","executionInfo":{"status":"ok","timestamp":1688978145128,"user_tz":-360,"elapsed":434,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}}},"outputs":[],"source":["import pandas as pd\n","import requests"]},{"cell_type":"code","source":["def GenerateTitle(paragraph):\n","  # API endpoint\n","  url = 'https://api.openai.com/v1/engines/davinci/completions'\n","\n","  # Your OpenAI API key\n","  api_key = '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'\n","\n","  # Your input paragraph\n","  #paragraph = \"The Padma Bridge is a major infrastructure project in Bangladesh that aims to connect the country's southwest region, including the capital city Dhaka, with the country's southeastern and southwestern regions. Spanning the mighty Padma River, the bridge will significantly improve transportation and trade links, enhance economic growth, and facilitate the movement of goods and people. With a total length of around 6.15 kilometers, the Padma Bridge is designed as a multipurpose bridge accommodating both road and rail transport. It will serve as a vital link on the Asian Highway and Trans-Asian Railway networks, connecting Bangladesh with neighboring countries and fostering regional connectivity.\"\n","\n","  # Parameters for the API request\n","  data = {\n","      'prompt': paragraph,\n","      'max_tokens': 20,\n","      'temperature': 0.7,\n","      'top_p': 1.0,\n","      'n': 1,\n","      'stop': None,\n","  }\n","\n","  # Headers with authorization\n","  headers = {\n","      'Content-Type': 'application/json',\n","      'Authorization': f'Bearer {api_key}',\n","  }\n","\n","  # Send POST request to the API\n","  response = requests.post(url, json=data, headers=headers)\n","  data = response.json()\n","  # print(data)\n","\n","  # Extract the generated title from the API response\n","  choices = data['choices']\n","  if choices:\n","      title = choices[0]['text']\n","      return title\n","      #print(\"Generated Title:\", title)\n","  else:\n","    return \"NULL\"\n","    #print(\"No title generated.\")"],"metadata":{"id":"1qvewAJ38gHV","executionInfo":{"status":"ok","timestamp":1688978535735,"user_tz":-360,"elapsed":404,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["import requests\n","\n","# Your Facebook access token\n","access_token = 'EAADOTzPOrjcBAKj2uEpB7rhiH8AIvbCEXsmmvXg2DMQJN9IMc8HciXwbZBPhfbhbxZC1WtD67irwKDlp5V3VNATamIsFZBKnAk1buMcQ9wAJZBgzkuvcmyZAZCuJdieTuFLKxeMLHYafZAJXgHEhyt95JyzUG35ejdITDkRgBziePautwpPeUbTy9XjytyMuOZCEvXv9oJ9jawZDZD'\n","\n","# ID of your Facebook page\n","page_id = '109656981889479'\n","\n","# API endpoint URL\n","url = f'https://graph.facebook.com/{page_id}/feed'\n","\n","# Parameters for the API request\n","params = {\n","    'access_token': access_token,\n","    'fields': 'id,message,created_time,attachments{media_type,url,subattachments{media_type,url}}',\n","    'limit': 10\n","}\n","\n","# Send GET request to the API\n","response = requests.get(url, params=params)\n","posts_data = []\n","# Check if the request was successful (status code 200)\n","if response.status_code == 200:\n","    data = response.json()\n","    posts = data['data']\n","    for post in posts:\n","        post_data = []\n","        post_id = post['id']\n","        message = post.get('message', '')\n","        created_time = post.get('created_time', '')\n","        attachments = post.get('attachments', {}).get('data', [])\n","        for attachment in attachments:\n","            media_type = attachment.get('media_type', '')\n","            if media_type == 'photo':  # Check if the attachment is a photo\n","                media_url = attachment.get('url', '')\n","                #print(f'Post ID: {post_id}')\n","                post_data.append(post_id)\n","                #print(f'Message: {message}')\n","                post_data.append(message)\n","                title = GenerateTitle(message)\n","                post_data.append(title)\n","                #print(f'Created Time: {created_time}')\n","                post_data.append(created_time)\n","                #print(f'Image URL: {media_url}')\n","                post_data.append(media_type)\n","                post_data.append(media_url)\n","                #print('---')\n","            elif media_type == 'album':  # Check if the attachment is an album\n","                subattachments = attachment.get('subattachments', {}).get('data', [])\n","                for subattachment in subattachments:\n","                    sub_media_type = subattachment.get('media_type', '')\n","                    if sub_media_type == 'photo':  # Check if the subattachment is a photo\n","                        sub_media_url = subattachment.get('url', '')\n","                        #print(f'Post ID: {post_id}')\n","                        post_data.append(post_id)\n","                        #print(f'Message: {message}')\n","                        post_data.append(message)\n","                        title = GenerateTitle(message)\n","                        post_data.append(title)\n","                        #print(f'Created Time: {created_time}')\n","                        post_data.append(created_time)\n","                        #print(f'Image URL: {sub_media_url}')\n","                        post_data.append(media_type)\n","                        post_data.append(sub_media_url)\n","                        #print('---')\n","            elif media_type == 'video':  # Check if the attachment is a video\n","                media_url = attachment.get('url', '')\n","                #print(f'Post ID: {post_id}')\n","                post_data.append(post_id)\n","                #print(f'Message: {message}')\n","                post_data.append(message)\n","                title = GenerateTitle(message)\n","                post_data.append(title)\n","                #print(f'Created Time: {created_time}')\n","                post_data.append(created_time)\n","                #print(f'Video URL: {media_url}')\n","                post_data.append(media_type)\n","                post_data.append(media_url)\n","                #print('---')\n","        posts_data.append(post_data)\n","    print(\"Data Scrape Successfully!\")\n","else:\n","    print('Error occurred while accessing the API.')\n"],"metadata":{"id":"XO3EkI9Khg-R","executionInfo":{"status":"ok","timestamp":1688978547045,"user_tz":-360,"elapsed":7914,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"46fe59d0-595d-4b8e-8864-ac218ffed5b1"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Scrape Successfully!\n"]}]},{"cell_type":"code","source":["data_df = pd.DataFrame(posts_data,columns=[\"post id\",\"message\",\"title\",\"created time\",\"media type\",\"media url\"])\n","data_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":580},"id":"pCgF6jhwhlWp","executionInfo":{"status":"ok","timestamp":1688978548587,"user_tz":-360,"elapsed":6,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}},"outputId":"ede4f434-95b4-4568-fcb3-ec60b76b0629"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                           post id  \\\n","0                             None   \n","1  109656981889479_148016524744053   \n","2  109656981889479_148016501410722   \n","3  109656981889479_137119619167077   \n","4  109656981889479_134127852799587   \n","5  109656981889479_132683846277321   \n","6  109656981889479_127299000149139   \n","7  109656981889479_125398233672549   \n","8  109656981889479_124462583766114   \n","9  109656981889479_116639147857929   \n","\n","                                             message  \\\n","0                                               None   \n","1                          Nine - The End / Teaser .   \n","2                          Nine - The End / Teaser .   \n","3  Dream Loop / মায়াজাল .\\n\\nhttps://youtu.be/fr6...   \n","4                 DreamLoop / মায়াজাল - Story Line .   \n","5           Te-Mangu .\\nhttps://youtu.be/N-L4ZfTNgV8   \n","6                                    Detective DNA .   \n","7                             Detective DNA - Teaser   \n","8                           SEE YOU SOON ...........   \n","9  A psychopath can tell what you're thinking but...   \n","\n","                                               title  \\\n","0                                               None   \n","1   Teaser: \"The End\"\\n\\nTeaser: \"The End\" . Nine...   \n","2            . . . . . . . . . . . . . . . . . . . .   \n","3                \\n\\n\\n\\n36.\\n\\nShudhu Shreeman / শু   \n","4        MP3 Play Download\\n\\n\\n\\n\\n\\nDownload \"মায়া   \n","5                                                 \\n   \n","6   . .\\n\\n. . . Crime Scene Investigators . . .\\...   \n","7   Trailer\\n\\nA new police series about a female...   \n","8                 \\n\\nA.P.M.D.S.\\n\\nTHANKS TO MY FRI   \n","9  \\n\\nA psychopath can tell what you're thinking...   \n","\n","               created time media type  \\\n","0                      None       None   \n","1  2023-01-20T18:01:36+0000      video   \n","2  2023-01-20T18:01:14+0000      video   \n","3  2022-12-15T13:00:02+0000      photo   \n","4  2022-12-06T05:33:26+0000      video   \n","5  2022-12-01T13:00:22+0000      photo   \n","6  2022-11-14T13:03:42+0000      video   \n","7  2022-11-08T13:28:40+0000      video   \n","8  2022-11-05T14:28:34+0000      photo   \n","9  2022-10-01T12:45:55+0000      video   \n","\n","                                           media url  \n","0                                               None  \n","1  https://www.facebook.com/238273589051679/video...  \n","2     https://www.facebook.com/reel/713614703697246/  \n","3  https://www.facebook.com/photo.php?fbid=137120...  \n","4  https://www.facebook.com/238273589051679/video...  \n","5  https://www.facebook.com/photo.php?fbid=132683...  \n","6  https://www.facebook.com/238273589051679/video...  \n","7  https://www.facebook.com/238273589051679/video...  \n","8  https://www.facebook.com/photo.php?fbid=124462...  \n","9  https://www.facebook.com/238273589051679/video...  "],"text/html":["\n","  <div id=\"df-6805fb52-0f5f-4eaa-86ac-5c8df4157ca5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>post id</th>\n","      <th>message</th>\n","      <th>title</th>\n","      <th>created time</th>\n","      <th>media type</th>\n","      <th>media url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>109656981889479_148016524744053</td>\n","      <td>Nine - The End / Teaser .</td>\n","      <td>Teaser: \"The End\"\\n\\nTeaser: \"The End\" . Nine...</td>\n","      <td>2023-01-20T18:01:36+0000</td>\n","      <td>video</td>\n","      <td>https://www.facebook.com/238273589051679/video...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>109656981889479_148016501410722</td>\n","      <td>Nine - The End / Teaser .</td>\n","      <td>. . . . . . . . . . . . . . . . . . . .</td>\n","      <td>2023-01-20T18:01:14+0000</td>\n","      <td>video</td>\n","      <td>https://www.facebook.com/reel/713614703697246/</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>109656981889479_137119619167077</td>\n","      <td>Dream Loop / মায়াজাল .\\n\\nhttps://youtu.be/fr6...</td>\n","      <td>\\n\\n\\n\\n36.\\n\\nShudhu Shreeman / শু</td>\n","      <td>2022-12-15T13:00:02+0000</td>\n","      <td>photo</td>\n","      <td>https://www.facebook.com/photo.php?fbid=137120...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>109656981889479_134127852799587</td>\n","      <td>DreamLoop / মায়াজাল - Story Line .</td>\n","      <td>MP3 Play Download\\n\\n\\n\\n\\n\\nDownload \"মায়া</td>\n","      <td>2022-12-06T05:33:26+0000</td>\n","      <td>video</td>\n","      <td>https://www.facebook.com/238273589051679/video...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>109656981889479_132683846277321</td>\n","      <td>Te-Mangu .\\nhttps://youtu.be/N-L4ZfTNgV8</td>\n","      <td>\\n</td>\n","      <td>2022-12-01T13:00:22+0000</td>\n","      <td>photo</td>\n","      <td>https://www.facebook.com/photo.php?fbid=132683...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>109656981889479_127299000149139</td>\n","      <td>Detective DNA .</td>\n","      <td>. .\\n\\n. . . Crime Scene Investigators . . .\\...</td>\n","      <td>2022-11-14T13:03:42+0000</td>\n","      <td>video</td>\n","      <td>https://www.facebook.com/238273589051679/video...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>109656981889479_125398233672549</td>\n","      <td>Detective DNA - Teaser</td>\n","      <td>Trailer\\n\\nA new police series about a female...</td>\n","      <td>2022-11-08T13:28:40+0000</td>\n","      <td>video</td>\n","      <td>https://www.facebook.com/238273589051679/video...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>109656981889479_124462583766114</td>\n","      <td>SEE YOU SOON ...........</td>\n","      <td>\\n\\nA.P.M.D.S.\\n\\nTHANKS TO MY FRI</td>\n","      <td>2022-11-05T14:28:34+0000</td>\n","      <td>photo</td>\n","      <td>https://www.facebook.com/photo.php?fbid=124462...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>109656981889479_116639147857929</td>\n","      <td>A psychopath can tell what you're thinking but...</td>\n","      <td>\\n\\nA psychopath can tell what you're thinking...</td>\n","      <td>2022-10-01T12:45:55+0000</td>\n","      <td>video</td>\n","      <td>https://www.facebook.com/238273589051679/video...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6805fb52-0f5f-4eaa-86ac-5c8df4157ca5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6805fb52-0f5f-4eaa-86ac-5c8df4157ca5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6805fb52-0f5f-4eaa-86ac-5c8df4157ca5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["data_df.to_csv(\"/content/facebook-post-data.csv\")"],"metadata":{"id":"CyMXXzuSt64f","executionInfo":{"status":"ok","timestamp":1688978790672,"user_tz":-360,"elapsed":477,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["# Generate Title From Post Content"],"metadata":{"id":"E_Mp3Yq4nxnR"}},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDVCaQVNi-GI","executionInfo":{"status":"ok","timestamp":1688971522603,"user_tz":-360,"elapsed":10395,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}},"outputId":"0061f323-f0ab-4c7e-b93c-4dbb7fab0106"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m132.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","def generate_title(text):\n","    # Load the pre-trained summarization model\n","    summarizer = pipeline(\"summarization\")\n","\n","    # Set the maximum length of the generated summary\n","    max_length = 14\n","\n","    # Generate the summary using the text\n","    summary = summarizer(text, max_length=max_length, min_length=10, do_sample=False)\n","\n","    # Extract the generated summary\n","    title = summary[0]['summary_text']\n","\n","    return title\n","\n","# Example usage\n","text = \"A text can be any example of written or spoken language, from something as complex as a book or legal document to something as simple as the body of an email or the words on the back of a cereal box.\"\n","title = generate_title(text)\n","print(title)\n"],"metadata":{"id":"v97ZQir1hpJQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688971704307,"user_tz":-360,"elapsed":8207,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}},"outputId":"8af0c7bc-2766-43c5-ea30-de8ddb215634"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]},{"output_type":"stream","name":"stdout","text":[" A text can be any example of written or spoken language\n"]}]},{"cell_type":"code","source":["\n","\n","import requests\n","\n","# API endpoint\n","url = 'https://api.openai.com/v1/engines/davinci/completions'\n","\n","# Your OpenAI API key\n","api_key = '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'\n","\n","# Your input paragraph\n","paragraph = \"The Padma Bridge is a major infrastructure project in Bangladesh that aims to connect the country's southwest region, including the capital city Dhaka, with the country's southeastern and southwestern regions. Spanning the mighty Padma River, the bridge will significantly improve transportation and trade links, enhance economic growth, and facilitate the movement of goods and people. With a total length of around 6.15 kilometers, the Padma Bridge is designed as a multipurpose bridge accommodating both road and rail transport. It will serve as a vital link on the Asian Highway and Trans-Asian Railway networks, connecting Bangladesh with neighboring countries and fostering regional connectivity.\"\n","\n","# Parameters for the API request\n","data = {\n","    'prompt': paragraph,\n","    'max_tokens': 20,\n","    'temperature': 0.7,\n","    'top_p': 1.0,\n","    'n': 1,\n","    'stop': None,\n","}\n","\n","# Headers with authorization\n","headers = {\n","    'Content-Type': 'application/json',\n","    'Authorization': f'Bearer {api_key}',\n","}\n","\n","# Send POST request to the API\n","response = requests.post(url, json=data, headers=headers)\n","data = response.json()\n","# print(data)\n","\n","# Extract the generated title from the API response\n","choices = data['choices']\n","if choices:\n","    title = choices[0]['text']\n","    print(\"Generated Title:\", title)\n","else:\n","    print(\"No title generated.\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5Pi93jWxggn","executionInfo":{"status":"ok","timestamp":1688976986158,"user_tz":-360,"elapsed":1280,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}},"outputId":"75778bea-be5b-4e3f-ee74-e8a635e1e684"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Title:  The structure consists of five lanes, two of which are reserved for rail transport. It will also serve\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","def generate_title(text):\n","    # Load the pre-trained T5 model for summarization\n","    summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\")\n","\n","    # Set the maximum length of the generated summary\n","    max_length = 10\n","\n","    # Generate the summary using the text\n","    summary = summarizer(text, max_length=max_length, min_length=10, do_sample=True)\n","\n","    # Extract the generated summary\n","    title = summary[0]['summary_text']\n","\n","    return title\n","\n","# Example usage\n","text = \"A text can be any example of written or spoken language, from something as complex as a book or legal document to something as simple as the body of an email or the words on the back of a cereal box.\"\n","title = generate_title(text)\n","print(title)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-Pa8mipkXWI","executionInfo":{"status":"ok","timestamp":1688971954245,"user_tz":-360,"elapsed":3871,"user":{"displayName":"Saifur Rahman","userId":"00455780785921939084"}},"outputId":"43f0f0e0-f5b8-4f44-e55b-8c8f5c7e877a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["a text can be any example of written\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","\n","train_dataset = [\n","    (\"Input text 1\", \"Target title 1\"),\n","    (\"Input text 2\", \"Target title 2\"),\n","    # Add more training examples as needed\n","]\n","\n","# Define the Pointer-Generator Network model\n","class PointerGeneratorNetwork(Model):\n","    def __init__(self, vocab_size, embedding_dim, hidden_units):\n","        super(PointerGeneratorNetwork, self).__init__()\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n","        self.decoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n","        self.attention = Attention()\n","        self.pointer = Dense(1, activation='sigmoid')\n","        self.vocab_dist = Dense(vocab_size, activation='softmax')\n","\n","    def call(self, inputs):\n","        enc_input, dec_input = inputs\n","\n","        enc_embed = self.embedding(enc_input)\n","        enc_output, enc_state_h, enc_state_c = self.encoder(enc_embed)\n","\n","        dec_embed = self.embedding(dec_input)\n","        dec_output, _, _ = self.decoder(dec_embed, initial_state=[enc_state_h, enc_state_c])\n","\n","        attention_weights = self.attention([dec_output, enc_output])\n","\n","        pointer_prob = self.pointer(dec_output)\n","        vocab_prob = self.vocab_dist(dec_output)\n","\n","        combined_prob = tf.concat([pointer_prob, vocab_prob], axis=-1)\n","        final_prob = tf.reduce_sum(combined_prob * attention_weights, axis=-1)\n","\n","        return final_prob, attention_weights\n","\n","# Example usage\n","vocab_size = 10000  # Size of the vocabulary\n","embedding_dim = 300  # Dimension of the word embeddings\n","hidden_units = 256  # Number of hidden units in LSTM layers\n","\n","# Create an instance of the PointerGeneratorNetwork model\n","model = PointerGeneratorNetwork(vocab_size, embedding_dim, hidden_units)\n","\n","# Define the loss function and optimizer for training\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Define a training loop\n","@tf.function\n","def train_step(inputs, labels):\n","    with tf.GradientTape() as tape:\n","        probs, _ = model(inputs)\n","        loss = loss_fn(labels, probs)\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    return loss\n","\n","# Training loop example\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for inputs, labels in train_dataset:\n","        loss = train_step(inputs, labels)\n","        # Additional training code goes here\n","\n","# Generating titles example\n","input_text = \"This is an example input text.\"\n","input_sequence = preprocess(input_text)  # Preprocess the input text into a sequence\n","input_sequence = tf.expand_dims(input_sequence, axis=0)  # Add batch dimension\n","start_token = tf.constant([[start_token_id]])  # Start token for decoding\n","probs, _ = model([input_sequence, start_token])\n","generated_title = tf.argmax(probs, axis=-1).numpy()[0]  # Convert predicted token IDs to text\n","\n"],"metadata":{"id":"mEPFzNvBlfz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","\n","# Define the Seq2Seq model\n","class Seq2SeqModel(Model):\n","    def __init__(self, vocab_size, embedding_dim, hidden_units):\n","        super(Seq2SeqModel, self).__init__()\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.encoder = LSTM(hidden_units, return_state=True)\n","        self.decoder = LSTM(hidden_units, return_sequences=True)\n","        self.output_layer = Dense(vocab_size, activation='softmax')\n","\n","    def call(self, inputs):\n","        encoder_input, decoder_input = inputs\n","\n","        encoder_embed = self.embedding(encoder_input)\n","        _, encoder_state_h, encoder_state_c = self.encoder(encoder_embed)\n","\n","        decoder_embed = self.embedding(decoder_input)\n","        decoder_output = self.decoder(decoder_embed, initial_state=[encoder_state_h, encoder_state_c])\n","\n","        output = self.output_layer(decoder_output)\n","\n","        return output\n","\n","# Example usage\n","vocab_size = 10000  # Size of the vocabulary\n","embedding_dim = 300  # Dimension of the word embeddings\n","hidden_units = 256  # Number of hidden units in LSTM layers\n","\n","# Create an instance of the Seq2Seq model\n","model = Seq2SeqModel(vocab_size, embedding_dim, hidden_units)\n","\n","# Define the loss function and optimizer for training\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Define a training loop\n","@tf.function\n","def train_step(inputs, labels):\n","    with tf.GradientTape() as tape:\n","        predictions = model(inputs)\n","        loss = loss_fn(labels, predictions)\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    return loss\n","\n","# Training loop example\n","for epoch in range(num_epochs):\n","    for inputs, labels in train_dataset:\n","        loss = train_step(inputs, labels)\n","        # Additional training code goes here\n","\n","# Generating titles example\n","input_text = \"This is an example input text.\"\n","input_sequence = preprocess(input_text)  # Preprocess the input text into a sequence\n","input_sequence = tf.expand_dims(input_sequence, axis=0)  # Add batch dimension\n","start_token = tf.constant([[start_token_id]])  # Start token for decoding\n","output = model([input_sequence, start_token])\n","generated_title = tf.argmax(output, axis=-1).numpy()[0]  # Convert predicted token IDs to text\n","\n"],"metadata":{"id":"rY7ewbO4mwGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer, TFBertLMHeadModel\n","\n","# Load the pre-trained BERT model and tokenizer\n","model_name = 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = TFBertLMHeadModel.from_pretrained(model_name, is_decoder=True)\n","\n","def generate_title(text):\n","    # Tokenize the input text\n","    inputs = tokenizer.encode_plus(\n","        text,\n","        max_length=512,\n","        truncation=True,\n","        padding='max_length',\n","        return_tensors='tf'\n","    )\n","\n","    # Adjust the maximum length based on the length of the input text\n","    max_length = min(20, inputs['input_ids'].shape[1])\n","\n","    # Generate the title\n","    outputs = model.generate(\n","        inputs['input_ids'],\n","        attention_mask=inputs['attention_mask'],\n","        max_length=max_length,\n","        num_beams=5,\n","        early_stopping=True\n","    )\n","\n","    # Decode the generated title\n","    generated_title = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    return generated_title\n","\n","# Example usage\n","text = \"This is a sample text from which we want to generate a title using BERT.\"\n","title = generate_title(text)\n","print(title)\n"],"metadata":{"id":"vURSQJ5Eowjp"},"execution_count":null,"outputs":[]}]}